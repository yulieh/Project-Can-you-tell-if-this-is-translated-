# Project: Can you tell if this is written by a BOT? 

# **Contents**
- Objective 
- How it Works 
- Implications 
- Limits and Developments 
- 
# **Objective**
The goal of this repository is to introduce a program that asks a user to identify a number of random text from a twee if it is auto-generated or not. The user will then be asked if they are native or non-native speakers. 

# **How it Works**
The user is shown a number of random English texts extracted from twitter. By entering either "Y" or "N" the user needs to determine if the text was auto-generated or not. Subsequently, the user needs to put in the information whether they are native or non-native speakers. 
At the end, the program saves the results and the responses between native/non-native speakers are presented as a scatter plot: 

# **Implications**
1. Implication: 
Texts that had significant gaps between responses of non-native and native users can show how different nuance, macro linguistic components of auto-generated texts are perceived. 

2. Implication: 
Data for natural language process can be feed in especially based on texts where native speakers gave a high response identifying the text as auto-generated. 

# **Further Developments**
Nuances, change in language can be further detected with different type of users based on age group and different demographics. Limitations and questions remain as how users define as native and non-natives.
Further researches can be made using different languages for the texts. 
